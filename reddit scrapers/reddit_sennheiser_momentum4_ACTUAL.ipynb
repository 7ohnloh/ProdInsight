{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1kND1SOYqKF_HEdDVZy_ayWfZoPQ5AeZq","timestamp":1745606362042}],"authorship_tag":"ABX9TyOvTUxAxE15gw7YB0ST4vJ/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jCl2g5iOKxWM","executionInfo":{"status":"ok","timestamp":1745607650628,"user_tz":-480,"elapsed":88886,"user":{"displayName":"aids letsgo","userId":"02789679334540883432"}},"outputId":"bcbd6d6b-1299-47b3-eb22-716bd521b4d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Fetching: Buying Them All: Technics AZ100, Bowers & Wilkins Pi8, Devialet Gemini II, Denon Perl Pro, Sennheiser TW 4, Bang & Olufsen Beoplay EX/XI\n","Fetching: A comprehensive review of 4 cars in 7 years: Giulia Quadrifoglio vs GR Supra vs ND2 MX5 vs BRZ\n","Fetching: Sennheiser MOMENTUM 4 Wireless: Review\n","Fetching: Overwhelmed. Can you please help me? B&W pi8, Technics AZ80/100, JBL Tour Pro 3, Denon Perl Pro, Sennheiser Momentum, or Apple AirPods Pro 2? \n","Fetching: Final review of the head to head comparison of the Bowers and Wilkins PX7S2e and Sennheiser Momentum 4\n","Fetching: Sennheiser Momentum True wireless 4\n","Fetching: Sennheiser Momentum 4 Marked as Frequently Returned Item on Amazon\n","Fetching: Momentum 4 for $200\n","Fetching: Finally had the opportunity to buy sennheiser Momentum 4!\n","Fetching: Looking into buying Sennheiser Momentum 4 but am a bit scared after reading conflicting reviews. For those of you who bought them - are they worth it? Is the listening experience good - sound-wise? Did the app problem get fixed/ are the headphones less buggy now?\n","\n","Done. 10 Reddit posts scraped.\n","Threaded comment data saved to CSV at: /content/drive/MyDrive/Colab/DAI_AID/extracted_data/reddit_reviews/reddit_sennheiser_momentum4_threaded_comments.csv\n"]}],"source":["# --------------------------------------------\n","# 0. Install Required Packages\n","# --------------------------------------------\n","!pip install --quiet praw google-api-python-client openai \\\n","    scikit-learn==1.3.2 matplotlib seaborn \\\n","    sentence-transformers transformers gensim nltk wordcloud textblob\n","\n","!pip install --upgrade pandas\n","\n","# --------------------------------------------\n","# 1. Import Libraries & Mount Google Drive\n","# --------------------------------------------\n","from google.colab import drive\n","import os, re\n","import pandas as pd\n","import nltk\n","from nltk.corpus import stopwords\n","from textblob import TextBlob\n","from wordcloud import WordCloud\n","from sentence_transformers import SentenceTransformer\n","from sklearn.cluster import KMeans\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import praw\n","import gensim\n","from gensim import corpora\n","\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","\n","drive.mount('/content/drive', force_remount=True)\n","\n","output_dir = '/content/drive/MyDrive/Colab/DAI_AID/extracted_data/reddit_reviews'\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# --------------------------------------------\n","# 2. Load API Keys\n","# --------------------------------------------\n","reddit_keys = {}\n","with open('/content/drive/MyDrive/Colab/DAI_AID/keys/reddit_keys.txt') as f:\n","    for line in f:\n","        if '=' in line:\n","            key, value = line.strip().split('=', 1)\n","            reddit_keys[key] = value\n","\n","# --------------------------------------------\n","# 3. Search & Collect Comments\n","# --------------------------------------------\n","reddit = praw.Reddit(\n","    client_id=reddit_keys['client_id'],\n","    client_secret=reddit_keys['client_secret'],\n","    user_agent=reddit_keys['user_agent'],\n","    check_for_async=False\n",")\n","\n","search_term = \"sennheiser momentum 4 reviews\"\n","subreddit = reddit.subreddit('all')\n","search_results = subreddit.search(search_term, limit=10)\n","\n","all_data = []\n","def extract_comment_thread(comment):\n","    return {\n","        'body': comment.body,\n","        'author': str(comment.author),\n","        'replies': [extract_comment_thread(reply) for reply in comment.replies if hasattr(reply, \"body\")]\n","    }\n","\n","for post in search_results:\n","    print(f\"Fetching: {post.title}\")\n","    comments = []\n","    try:\n","        post.comments.replace_more(limit=None)\n","        for top_comment in post.comments:\n","            if hasattr(top_comment, \"body\"):\n","                comments.append(extract_comment_thread(top_comment))\n","    except Exception as e:\n","        print(f\"Error: {e}\")\n","    all_data.append({\n","        'title': post.title,\n","        'url': f\"https://www.reddit.com{post.permalink}\",\n","        'post_id': post.id,\n","        'comments': comments\n","    })\n","\n","print(f\"\\nDone. {len(all_data)} Reddit posts scraped.\")\n","\n","# --------------------------------------------\n","# 4. Clean & Process Comments (Thread Flattening)\n","# --------------------------------------------\n","def flatten_comments(comments, post_id, post_title, parent_id=None, depth=0):\n","    rows = []\n","    for comment in comments:\n","        row = {\n","            'post_id': post_id,\n","            'post_title': post_title,\n","            'comment_author': comment.get('author'),\n","            'comment_body': comment.get('body'),\n","            'parent_comment_id': parent_id,\n","        }\n","        rows.append(row)\n","        if 'replies' in comment and isinstance(comment['replies'], list):\n","            rows += flatten_comments(comment['replies'], post_id, post_title, parent_id=comment.get('body')[:50], depth=depth + 1)\n","    return rows\n","\n","csv_rows = []\n","for post in all_data:\n","    csv_rows += flatten_comments(post['comments'], post['post_id'], post['title'])\n","\n","df = pd.DataFrame(csv_rows)\n","\n","# --------------------------------------------\n","# 5. Sentiment Score + Weight\n","# --------------------------------------------\n","def preserve_meaningful_clean(text):\n","    text = str(text)\n","    text = re.sub(r\"http\\S+\", \"\", text)\n","    text = re.sub(r\"\\s+\", \" \", text)\n","    text = re.sub(r\"\\[removed\\]|\\[deleted\\]\", \"\", text)\n","    return text.strip()\n","\n","def get_sentiment_score(text):\n","    blob = TextBlob(text)\n","    return blob.sentiment.polarity\n","\n","df['cleaned'] = df['comment_body'].apply(preserve_meaningful_clean)\n","df['sentiment'] = df['cleaned'].apply(get_sentiment_score)\n","df['length'] = df['cleaned'].apply(lambda x: len(x.split()))\n","df['weight'] = (\n","    df['sentiment'] * 0.6 +\n","    (df['length'] / (df['length'].max() + 1)) * 0.4\n",")\n","\n","# --------------------------------------------\n","# 6. Save to Drive\n","# --------------------------------------------\n","output_path = f\"{output_dir}/reddit_sennheiser_momentum4_threaded_comments.csv\"\n","df.to_csv(output_path, index=False)\n","print(f\"Threaded comment data saved to CSV at: {output_path}\")\n"]}]}